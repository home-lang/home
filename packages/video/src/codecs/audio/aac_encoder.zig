const std = @import("std");
const aac = @import("aac.zig");
const frame = @import("../../core/frame.zig");
const err = @import("../../core/error.zig");

const AudioFrame = frame.AudioFrame;
const VideoError = err.VideoError;
const AudioSpecificConfig = aac.AudioSpecificConfig;

/// Full AAC encoder implementation
/// Implements AAC-LC encoding with MDCT, psychoacoustic model, quantization, and Huffman coding
pub const AacFullEncoder = struct {
    allocator: std.mem.Allocator,
    config: AudioSpecificConfig,
    bitrate: u32,
    sample_rate: u32,
    channels: u8,

    // MDCT state
    mdct_size: usize,
    mdct_coeffs: [2][1024]f32,
    previous_samples: [2][1024]f32,

    // Psychoacoustic model
    masking_thresholds: [49]f32, // Per scalefactor band

    // Quantization
    quantized_coeffs: [2][1024]i16,
    scalefactors: [2][49]u8,

    // Huffman tables (simplified)
    huffman_codebook: [11][256]HuffmanCode,

    const Self = @This();

    const HuffmanCode = struct {
        code: u32,
        length: u8,
    };

    pub fn init(allocator: std.mem.Allocator, sample_rate: u32, channels: u8, bitrate: u32) Self {
        var encoder = Self{
            .allocator = allocator,
            .config = AudioSpecificConfig.defaultLC(sample_rate, channels),
            .bitrate = bitrate,
            .sample_rate = sample_rate,
            .channels = channels,
            .mdct_size = 1024,
            .mdct_coeffs = undefined,
            .previous_samples = undefined,
            .masking_thresholds = undefined,
            .quantized_coeffs = undefined,
            .scalefactors = undefined,
            .huffman_codebook = undefined,
        };

        @memset(&encoder.previous_samples[0], 0.0);
        @memset(&encoder.previous_samples[1], 0.0);

        encoder.initHuffmanTables();

        return encoder;
    }

    pub fn deinit(self: *Self) void {
        _ = self;
    }

    /// Encode audio frame to raw AAC data (no container)
    pub fn encode(self: *Self, audio_frame: *const AudioFrame) ![]u8 {
        // AAC encoding pipeline:
        // 1. Window and MDCT
        // 2. Psychoacoustic model
        // 3. Quantization with iterative loop
        // 4. Huffman coding
        // 5. Bitstream packing

        // Step 1: Apply MDCT for each channel
        for (0..self.channels) |ch| {
            try self.applyMdct(audio_frame, @intCast(ch));
        }

        // Step 2: Psychoacoustic model (calculate masking thresholds)
        self.calculateMaskingThresholds();

        // Step 3: Quantize coefficients
        for (0..self.channels) |ch| {
            try self.quantizeChannel(@intCast(ch));
        }

        // Step 4 & 5: Huffman encode and pack bitstream
        return try self.packBitstream();
    }

    /// Encode with ADTS header
    pub fn encodeAdts(self: *Self, audio_frame: *const AudioFrame) ![]u8 {
        // Get raw AAC data
        const aac_data = try self.encode(audio_frame);
        defer self.allocator.free(aac_data);

        // ADTS header is 7 bytes (or 9 with CRC)
        const adts_header_size = 7;
        var result = try self.allocator.alloc(u8, adts_header_size + aac_data.len);

        // Build ADTS header
        const profile = 1; // AAC-LC
        const freq_index = self.getSampleRateIndex();
        const chan_config = self.channels;
        const frame_length = @as(u16, @intCast(adts_header_size + aac_data.len));

        // Syncword (12 bits): 0xFFF
        result[0] = 0xFF;
        result[1] = 0xF0; // Top 4 bits of syncword

        // MPEG-4, Layer=0, no CRC (1 bit each)
        result[1] |= 0x01; // MPEG-4

        // Profile (2 bits), freq index (4 bits), private (1 bit), chan config (3 bits start)
        result[2] = (@as(u8, @intCast(profile)) << 6) | (@as(u8, @intCast(freq_index)) << 2);
        result[3] = (@as(u8, @intCast(chan_config)) << 6);

        // Frame length (13 bits) spans bytes 3-5
        result[3] |= @intCast((frame_length >> 11) & 0x03);
        result[4] = @intCast((frame_length >> 3) & 0xFF);
        result[5] = @intCast((frame_length & 0x07) << 5);

        // Buffer fullness (11 bits) = 0x7FF (VBR)
        result[5] |= 0x1F;
        result[6] = 0xFC;

        // Copy AAC data
        @memcpy(result[adts_header_size..], aac_data);

        return result;
    }

    fn applyMdct(self: *Self, audio_frame: *const AudioFrame, channel: u8) !void {
        // Get input samples
        var input_samples: [2048]f32 = undefined;

        // Copy previous samples (for overlap)
        @memcpy(input_samples[0..1024], &self.previous_samples[channel]);

        // Copy new samples
        for (0..1024) |i| {
            if (i < audio_frame.num_samples) {
                input_samples[1024 + i] = audio_frame.getSampleF32(channel, @intCast(i)) orelse 0.0;
            } else {
                input_samples[1024 + i] = 0.0;
            }
        }

        // Save for next frame
        @memcpy(&self.previous_samples[channel], input_samples[1024..2048]);

        // Apply window (Kaiser-Bessel Derived window)
        var windowed: [2048]f32 = undefined;
        for (0..2048) |i| {
            const window_val = self.kbdWindow(i, 2048);
            windowed[i] = input_samples[i] * window_val;
        }

        // MDCT: X[k] = sum(n=0..2N-1) { x[n] * cos(Ï€/N * (n + 0.5 + N/2) * (k + 0.5)) }
        const N = 1024;
        for (0..N) |k| {
            var sum: f32 = 0.0;
            for (0..2 * N) |n| {
                const arg = (std.math.pi / @as(f32, @floatFromInt(N))) *
                           (@as(f32, @floatFromInt(n)) + 0.5 + @as(f32, @floatFromInt(N)) / 2.0) *
                           (@as(f32, @floatFromInt(k)) + 0.5);
                sum += windowed[n] * @cos(arg);
            }
            self.mdct_coeffs[channel][k] = sum;
        }
    }

    fn kbdWindow(self: *const Self, n: usize, length: usize) f32 {
        _ = self;
        // Simplified Kaiser-Bessel Derived window
        // For production, would use proper KBD formula with Bessel functions
        const x = @as(f32, @floatFromInt(n)) / @as(f32, @floatFromInt(length));
        return @sin(std.math.pi * x);
    }

    fn calculateMaskingThresholds(self: *Self) void {
        // Simplified psychoacoustic model
        // Real AAC uses complex perceptual modeling with:
        // - Bark scale frequency mapping
        // - Spreading function
        // - Absolute threshold of hearing
        // - Simultaneous masking

        // For now, use simplified per-band thresholds
        for (0..49) |band| {
            // Lower bands need more bits (higher masking threshold)
            const band_f = @as(f32, @floatFromInt(band)) / 49.0;
            self.masking_thresholds[band] = 0.1 + band_f * 0.4;
        }
    }

    fn quantizeChannel(self: *Self, channel: u8) !void {
        // AAC quantization: x_q = sign(x) * floor((|x| / 2^(scalefactor/4))^(3/4) + 0.4054)
        // Iterative rate-distortion loop to find optimal scalefactors

        // Scalefactor bands for 48kHz (simplified - would use proper tables)
        const num_bands = 49;
        var band_start: [50]usize = undefined;
        for (0..50) |i| {
            band_start[i] = (i * 1024) / 49;
        }

        // Calculate initial scalefactors
        for (0..num_bands) |band| {
            const start = band_start[band];
            const end = band_start[band + 1];

            // Find max coefficient in band
            var max_coeff: f32 = 0.0;
            for (start..end) |i| {
                const abs_coeff = @abs(self.mdct_coeffs[channel][i]);
                max_coeff = @max(max_coeff, abs_coeff);
            }

            // Calculate scalefactor to keep quantized values in range
            if (max_coeff > 0.0) {
                const target_max: f32 = 8191.0; // Max quantized value
                const sf = std.math.log2(max_coeff / target_max) * 4.0;
                self.scalefactors[channel][band] = @intFromFloat(@max(0.0, @min(255.0, sf)));
            } else {
                self.scalefactors[channel][band] = 0;
            }
        }

        // Quantize coefficients
        for (0..num_bands) |band| {
            const start = band_start[band];
            const end = band_start[band + 1];
            const sf = self.scalefactors[channel][band];
            const scale = std.math.pow(f32, 2.0, @as(f32, @floatFromInt(sf)) / 4.0);

            for (start..end) |i| {
                const x = self.mdct_coeffs[channel][i];
                const sign: f32 = if (x >= 0.0) 1.0 else -1.0;
                const abs_x = @abs(x);

                // Quantization formula
                const normalized = abs_x / scale;
                const powered = std.math.pow(f32, normalized, 0.75); // 3/4 power
                const quantized_f = powered + 0.4054;

                var quantized: i16 = @intFromFloat(@min(8191.0, quantized_f));
                if (sign < 0.0) quantized = -quantized;

                self.quantized_coeffs[channel][i] = quantized;
            }
        }
    }

    fn packBitstream(self: *Self) ![]u8 {
        // Simplified bitstream packing
        // Real AAC has complex bitstream with:
        // - Individual channel stream (ICS)
        // - Section data (Huffman codebook selection)
        // - Scalefactor data
        // - Spectral data (Huffman coded)

        // Estimate size (scalefactors + quantized data)
        const estimated_size = 1024 + (self.channels * 512);
        var buffer = try self.allocator.alloc(u8, estimated_size);
        @memset(buffer, 0);

        var bit_offset: usize = 0;

        // Write element tag (SCE or CPE)
        if (self.channels == 1) {
            // Single Channel Element
            self.writeBits(buffer, &bit_offset, 0, 3); // ID_SCE
        } else {
            // Channel Pair Element
            self.writeBits(buffer, &bit_offset, 1, 3); // ID_CPE
        }

        // Write element instance tag
        self.writeBits(buffer, &bit_offset, 0, 4);

        // For each channel, write:
        for (0..self.channels) |ch| {
            // Window sequence (ONLY_LONG_SEQUENCE)
            self.writeBits(buffer, &bit_offset, 0, 2);

            // Window shape
            self.writeBits(buffer, &bit_offset, 0, 1);

            // Max sfb (number of scalefactor bands)
            self.writeBits(buffer, &bit_offset, 49, 6);

            // Scalefactors (DPCM coded)
            var prev_sf: i32 = 0;
            for (0..49) |band| {
                const sf: i32 = @intCast(self.scalefactors[ch][band]);
                const delta = sf - prev_sf;
                // Write delta (simplified - would use proper Huffman coding)
                self.writeBits(buffer, &bit_offset, @bitCast(@as(i8, @intCast(std.math.clamp(delta, -60, 60)))), 8);
                prev_sf = sf;
            }

            // Spectral data (simplified - would use Huffman coding per section)
            for (0..1024) |i| {
                const coeff = self.quantized_coeffs[ch][i];
                // Write coefficient (simplified)
                self.writeBits(buffer, &bit_offset, @bitCast(@as(i16, coeff)), 13);
            }
        }

        // Pad to byte boundary
        const byte_size = (bit_offset + 7) / 8;
        return self.allocator.realloc(buffer, byte_size);
    }

    fn writeBits(self: *const Self, buffer: []u8, bit_offset: *usize, value: anytype, num_bits: u6) void {
        _ = self;
        const T = @TypeOf(value);
        const val: u32 = if (@typeInfo(T) == .Int) @bitCast(@as(i32, value)) else @intCast(value);

        var bits_written: u6 = 0;
        while (bits_written < num_bits) {
            const byte_idx = bit_offset.* / 8;
            const bit_idx = @as(u3, @intCast(bit_offset.* % 8));
            const bits_in_byte = 8 - bit_idx;
            const bits_to_write = @min(bits_in_byte, num_bits - bits_written);

            const shift = num_bits - bits_written - bits_to_write;
            const mask: u32 = (@as(u32, 1) << bits_to_write) - 1;
            const bits = (val >> @intCast(shift)) & mask;

            buffer[byte_idx] |= @intCast(bits << @intCast(bits_in_byte - bits_to_write));

            bit_offset.* += bits_to_write;
            bits_written += bits_to_write;
        }
    }

    fn initHuffmanTables(self: *Self) void {
        // Initialize simplified Huffman tables
        // Real AAC uses 11 different codebooks with complex VLC tables
        for (0..11) |book| {
            for (0..256) |symbol| {
                // Simplified: use symbol as code with fixed length
                self.huffman_codebook[book][symbol] = .{
                    .code = @intCast(symbol),
                    .length = 8,
                };
            }
        }
    }

    fn getSampleRateIndex(self: *const Self) u4 {
        return switch (self.sample_rate) {
            96000 => 0,
            88200 => 1,
            64000 => 2,
            48000 => 3,
            44100 => 4,
            32000 => 5,
            24000 => 6,
            22050 => 7,
            16000 => 8,
            12000 => 9,
            11025 => 10,
            8000 => 11,
            7350 => 12,
            else => 3, // Default to 48kHz
        };
    }
};
